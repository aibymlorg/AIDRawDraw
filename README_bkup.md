<div align="center">
<img width="1200" height="475" alt="GHBanner" src="https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6" />
</div>

# KnowKidDraw - AI Art Gallery

An interactive AI-powered application that analyzes children's drawings and provides encouraging, educational feedback from "Professor Panda," a friendly AI art teacher. The app supports multiple LLM providers and offers real-time conversation capabilities.

View your app in AI Studio: https://ai.studio/apps/drive/1POQrykocjrVNbKh5883eYFsjQRbNBUdF

## ğŸ—ï¸ Architecture

The application follows a modular React architecture with clean separation of concerns:

- **Frontend**: React 19 with TypeScript for type safety
- **Build Tool**: Vite for fast development and building
- **AI Integration**: Supports multiple LLM providers (Gemini AI, Ollama)
- **State Management**: React hooks for local state management
- **File Processing**: Built-in image handling and camera integration

## ğŸ› ï¸ Technology Stack

### Frontend
- **React 19** - Modern React with latest features
- **TypeScript** - Type-safe JavaScript
- **Vite** - Next-generation frontend tooling
- **CSS** - Custom styling (no framework dependencies)

### AI & APIs
- **Google Gemini AI** - Primary AI provider for image analysis
- **Ollama** - Local AI model support for privacy-focused deployments
- **@google/genai** - Official Google Generative AI SDK

### Development Tools
- **Node.js** - Runtime environment
- **npm** - Package management
- **ESLint** - Code linting (configured via TypeScript)

## ğŸ“ File Structure

```
knowkiddraw/
â”œâ”€â”€ components/              # React components
â”‚   â”œâ”€â”€ CameraModal.tsx     # Camera capture functionality
â”‚   â”œâ”€â”€ Conversation.tsx    # Chat interface
â”‚   â”œâ”€â”€ ExampleImages.tsx   # Sample images gallery
â”‚   â”œâ”€â”€ Header.tsx          # Application header
â”‚   â”œâ”€â”€ ImageUploader.tsx   # Image upload interface
â”‚   â””â”€â”€ Spinner.tsx         # Loading indicator
â”œâ”€â”€ services/               # AI service integrations
â”‚   â”œâ”€â”€ geminiService.ts    # Google Gemini AI integration
â”‚   â”œâ”€â”€ llmService.ts       # Unified LLM provider interface
â”‚   â””â”€â”€ ollamaService.ts    # Ollama local AI integration
â”œâ”€â”€ hooks/                  # Custom React hooks
â”œâ”€â”€ utils/                  # Utility functions
â”‚   â””â”€â”€ fileUtils.ts        # File processing utilities
â”œâ”€â”€ public/                 # Static assets
â”‚   â””â”€â”€ images/             # Example images and assets
â”œâ”€â”€ dist/                   # Build output directory
â”œâ”€â”€ App.tsx                 # Main application component
â”œâ”€â”€ constants.ts            # Application constants and prompts
â”œâ”€â”€ types.ts                # TypeScript type definitions
â”œâ”€â”€ index.tsx               # Application entry point
â”œâ”€â”€ index.html              # HTML template
â”œâ”€â”€ vite.config.ts          # Vite configuration
â”œâ”€â”€ tsconfig.json           # TypeScript configuration
â”œâ”€â”€ package.json            # Dependencies and scripts
â”œâ”€â”€ .env                    # Environment variables template
â””â”€â”€ .env.local              # Local environment variables
```

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** (version 16 or higher)
- **npm** (comes with Node.js)
- **API Key** for your chosen LLM provider:
  - Google Gemini AI API key, OR
  - Local Ollama installation

### Installation Steps

1. **Clone and navigate to the project:**
   ```bash
   git clone <repository-url>
   cd knowkiddraw
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Configure environment variables:**

   Copy the example environment file:
   ```bash
   cp .env .env.local
   ```

   Edit `.env.local` and configure your settings:
   ```env
   # LLM Provider Configuration
   REACT_APP_LLM_PROVIDER=gemini          # or 'ollama'

   # For Gemini AI (if using gemini provider)
   REACT_APP_GEMINI_API_KEY=your_gemini_api_key_here

   # For Ollama (if using ollama provider)
   REACT_APP_OLLAMA_URL=http://localhost:11434
   REACT_APP_OLLAMA_MODEL=llava
   ```

4. **Start the development server:**
   ```bash
   npm run dev
   ```

5. **Open your browser:**
   The application will automatically open at `http://localhost:5173`

### Production Build

1. **Build the application:**
   ```bash
   npm run build
   ```

2. **Preview the production build:**
   ```bash
   npm run preview
   ```

## ğŸ¯ Key Features

- **Multi-modal AI Analysis**: Upload images or use camera to capture children's drawings
- **Educational Feedback**: AI provides encouraging, age-appropriate responses
- **Multiple AI Providers**: Switch between Gemini AI and local Ollama models
- **Real-time Chat**: Interactive conversation interface with streaming responses
- **Example Gallery**: Pre-loaded sample images for quick testing
- **Camera Integration**: Built-in camera support for direct image capture
- **Type Safety**: Full TypeScript integration for robust development

## ğŸ”§ Configuration Options

### LLM Provider Setup

#### Using Google Gemini AI (Default)
1. Get API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Set `REACT_APP_LLM_PROVIDER=gemini` in `.env.local`
3. Set `REACT_APP_GEMINI_API_KEY=your_key` in `.env.local`

#### Using Ollama (Local AI)
1. Install [Ollama](https://ollama.ai/) locally
2. Pull a vision model: `ollama pull llava`
3. Set `REACT_APP_LLM_PROVIDER=ollama` in `.env.local`
4. Configure `REACT_APP_OLLAMA_URL` and `REACT_APP_OLLAMA_MODEL`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes and commit: `git commit -m 'Add feature'`
4. Push to your branch: `git push origin feature-name`
5. Create a Pull Request

## ğŸ“ License

This project is part of the AI Studio ecosystem. Please refer to the original license terms.
