# LLM Provider Configuration
# Choose 'gemini' for Google's Gemini API or 'ollama' for local Ollama server
REACT_APP_LLM_PROVIDER=gemini

# Gemini Configuration (required if using Gemini)
# Get your API key from https://aistudio.google.com/app/apikey
REACT_APP_GEMINI_API_KEY=AIzaSyDVrj5L7Ygm3DOCvYs0n5weQS-_1qPzkc0
GEMINI_API_KEY=AIzaSyDVrj5L7Ygm3DOCvYs0n5weQS-_1qPzkc0

# Ollama Configuration (required if using Ollama)
# Make sure Ollama server is running locally
REACT_APP_OLLAMA_URL=http://localhost:11434
REACT_APP_OLLAMA_MODEL=llama3.2-vision:latest
